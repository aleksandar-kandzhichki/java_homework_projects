import java.io.BufferedWriter;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileWriter;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.Vector;
import java.util.stream.Collectors;

import ca.pfv.spmf.algorithms.sequenceprediction.ipredict.database.Item;
import ca.pfv.spmf.algorithms.sequenceprediction.ipredict.predictor.CPT.CPTPlus.CPTPlusPredictor;

public class MiningHelper {

	Vector<String> mapper;
	Map<String, Integer> keys;
	int uniqueKeys;
	static String dataMiningInput = "dataInput.txt";
	static String dataMiningOutput = "dataOutput.txt";
	
	MiningHelper() {
		mapper = new Vector<String>();
		keys = new HashMap<String, Integer>();
		uniqueKeys = 0;
	}

	
	private void extendMapper(DataEntry entry) {
		// ATM we care only about the context, so we map only it!
		
		// if(!keys.containsKey(entry.component)) {mapper.add(entry.component);keys.put(entry.component, ++uniqueKeys);} 
		if(!keys.containsKey(entry.context)) {mapper.add(entry.context); keys.put(entry.context, ++uniqueKeys);} 
		// if(!keys.containsKey(entry.description)) {mapper.add(entry.description); keys.put(entry.description, ++uniqueKeys);} 
		// if(!keys.containsKey(entry.name)) {mapper.add(entry.name); keys.put(entry.name, ++uniqueKeys);} 
	}
	
	public void prepareFilesForDataMining(List<DataEntry> data) throws IOException {
		// BufferedWriter fileToPrepare = new BufferedWriter(new FileWriter(new File(dataMiningInput)));
		
		// prepare two-way mapping of keys to +Integers
		//data.stream().forEach(entry -> extendMapper(entry));
		
		// get sequencial rows needed for CPT+
		// List<String> rows = DataEntry.getSequenceRows(keys, data);
		// Iterator<String> rowsIter = rows.iterator();
		// while(rowsIter.hasNext()) {
			// fileToPrepare.write(rowsIter.next() + "\n");
		// }

		
		// fileToPrepare.close();
	}
	
	public List<Item> getItemsToTrain(List<DataEntry> data) {
		data.stream().forEach(entry -> extendMapper(entry));
		
		List<Item> rows = DataEntry.getSequenceItemList(keys, data);
		return rows;
	}
	
	public void runDataMining() {
		CPTPlusPredictor alg = new CPTPlusPredictor();
		//AlgoCMRules lib = new AlgoCptPlus();
		String input = dataMiningInput;
		String output = dataMiningOutput;
		
		try {
			alg.Train(trainingSequences)
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}
}
